# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FQkfsflIWraIYvXbhb9HjpNlCfgCcnsL
"""

#Para executar no google colab crie uma pasta em seu Drive
#com as informações de treino e teste
#from google.colab import drive
#drive.mount('/content/drive')

import os 
from skimage  import data, color, util, io, transform
from skimage.measure import label, regionprops, regionprops_table
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import model_selection, svm
from sklearn.svm import SVC
from sklearn.metrics import plot_confusion_matrix, precision_score, recall_score, accuracy_score, f1_score
import scipy.stats as stats
import matplotlib.cm as cm

np.random.seed(393) # seed de aleatoriedade prédefinida para replicar os resultados obtidos

"""Análise estatística das propriedades das imagens: após visualizar as amostras aplicamos as propriedades em cada conjunto de imagens da mesma classe para identificar padrões (por meio da média e desvio padrão)."""


"""Altere aqui o seu diretório base para utilizar do código"""
directorybase = '/home/diego/Desktop/SVM/mpeg7_4classes_aug_x8_work/' #/home/'nome do usuário'/Desktop/'pasta do trabalho'/mgpeg/



directory = directorybase + '/Train/apple'
apple = pd.DataFrame(0,index=range(0,126),columns=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory):
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      apple.iloc[index] = df1.iloc[0]
      index+=1


labels = pd.DataFrame(0,index=range(0,126),columns=['Labels']) 
labels.Labels = int(0)
apple['Labels'] = labels #cria uma coluna de labels com 0 para todas as maçãs
print("apple")
print(apple.describe()) ## solidity é o que melhor descreve a maçã

"""Decidimos observando a média e desvio padrão que as celuas são as melhores, euler_number, eccentricity, Extent, Solidity, labels"""

directory = directorybase +  'Train/bat'
bat = pd.DataFrame(0,index=range(0,126),columns=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      bat.iloc[index] = df1.iloc[0]
      index+=1

      
labels = pd.DataFrame(0,index=range(0,126),columns=['Labels']) 
labels.Labels = 1
bat['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

print("bat")
print(bat.describe()) ## solidity é o que melhor descreve a maçã

directory = directorybase +  '/Train/beetle'
beetle = pd.DataFrame(0,index=range(0,126),columns=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      beetle.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,126),columns=['Labels']) 
labels.Labels = 2
beetle['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

print("beetle")
print(beetle.describe()) ## solidity é o que melhor descreve a maçã

directory = directorybase + '/Train/bone'
bone = pd.DataFrame(0,index=range(0,126),columns=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['major_axis_length','minor_axis_length','euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      bone.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,126),columns=['Labels']) 
labels.Labels = 3
bone['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

print("bone")
print(bone.describe()) ## solidity é o que melhor descreve a maçã

"""Nó código imediatamente abaixo o conjunto não é mais splitado porque em vez da abordagem hold-out para validação é aplicado K-fold em: sklearn.model_selection.GridSearchCV (nos quadros que retornam matriz de confusão)"""

##SPLIT do conjunto de treino para validação e normalização de ambos

frames = [apple,bat,beetle,bone]
df_train = pd.concat(frames) #faz a união dos dataframes

df_train = (df_train.drop(columns=['major_axis_length','minor_axis_length'])).copy() #eliminando características que demonstraram não serem úteis para classificação

y_train = df_train.Labels #monta coluna de classificadores
X_train = df_train.drop(columns=['Labels']) #monta conjunto de dados sem os classificadores

# X_train, X_valid, y_train, y_valid = model_selection.train_test_split(df_data, df_labels, 
#                                                                         test_size=0.3, 
#                                                                         random_state=393) #no caso o test_size determina o tamanho do conjunto de validação
#normalização utilizando z_score (baseado na média e desvio padrão)
X_train_norm = stats.zscore(X_train) 
# X_valid_norm = stats.zscore(X_valid)

##montando conjunto de teste

##apple
directory = directorybase +  'Test/apple'
apple = pd.DataFrame(0,index=range(0,54),columns=['euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      apple.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,54),columns=['Labels']) 
labels.Labels = 0
apple['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

## bat
directory = directorybase + '/Test/bat'
bat = pd.DataFrame(0,index=range(0,54),columns=['euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      bat.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,54),columns=['Labels']) 
labels.Labels = 1
bat['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

##beetle
directory = directorybase +  '/Test/beetle'
beetle = pd.DataFrame(0,index=range(0,54),columns=['euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      beetle.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,54),columns=['Labels']) 
labels.Labels = 2
beetle['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

##bone
directory = directorybase +  '/Test/bone'
bone = pd.DataFrame(0,index=range(0,54),columns=['euler_number','eccentricity','extent','solidity'])
index=0
for filename in os.scandir(directory): 
    if filename.is_file(): 
      img = io.imread(filename.path)
      label_img = label(img)
      props = regionprops_table(label_img, properties=['euler_number','eccentricity','extent','solidity'])
      df1=pd.DataFrame(props)
      bone.iloc[index] = df1.iloc[0]
      index+=1

labels = pd.DataFrame(0,index=range(0,54),columns=['Labels']) 
labels.Labels = 3
bone['Labels'] = labels #cria uma coluna de labels com 1 para todos os morcegos

##unindo os dataframes em um só de teste
frames = [apple,bat,beetle,bone]
df_test = pd.concat(frames) #faz a união dos dataframes

##separando dados dos rótulos
y_test = df_test.Labels #monta coluna de classificadores
df_test_data = (df_test.drop(columns=['Labels'])).copy() #monta conjunto de dados sem os classificadores

##normalizando os dados de teste
X_test_norm = stats.zscore(df_test_data)

"""Classes:

0.   apple;
1.   bat;
2.   beetle;
3.   bone.

Próximos Passos:

0.   Split: separar de 20% a 30% do conjunto de treino para validar o modelo;
1.   Normalizar os parâmetros (sugiro Z-score);
2.   Aplicar o SVM (verificar parâmetros a serem ajustados);
3.   Validar;
4.   Imprimir matriz de Confusão.

OBS: (Obrigatório) Defina o argumento random_state=393 (consultar documentação scikit-learn)

Kernels do SVM (manipulações distintas para contextos distintos de dispersão dos dados):

1.  Polynomial Kernel: utilizado para classes não linearmente separáveis. Parâmetros de otimização = gamma(inclinação do plano),c(constante) e d é o grau polinomial;
2.  RBF(Radial Basis Function ou Gaussiano): é muito sensível a ruidos e seu parâmetro de espalhamento é muito sensível. Caso seja superestimado o Kernel perde a vantagem da análise não linear;
3.   Sigmoid: y atua como escala dos dados e c como parâmetro de deslocamento;
4.   Linear:

conferir: kernel {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} 


Notebook referência: https://github.com/joaofmari/SIN393_Introducao-a-visao-computacional_2022-2/blob/main/notebooks/Aula%2007%20-%20Classificadores%20K-NN%2C%20Bayes%20e%20SVM.ipynb
"""



##################Filtro que Obteve a melhor qualidade na analize da ácurácia####################



print('\n\n\nFiltro que Obteve a Maior acurácia em relação aos testados:\n\n\n')

##aplicando Gaussiano
param_grid = [
    {'C':[0.5,1,3,5,10,100],
     'gamma':['scale',1,0.1,0.01,0.001,0.0001],
     'kernel':['rbf']}
]
# CV = número de folds para validação (K-Fold), Verbose=0 faz retornar apenas a saída da melhor seleção de parametros
# Scoring=mediade de ranking das melhores combinações de parâmetros, param_grid=forma de leitura dos parâmetros sendo dicionário
# SVC=SVM sendo chamado para classificações

optimal_params = model_selection.GridSearchCV(
    SVC(random_state=393),
    param_grid,
    cv=10,
    scoring='accuracy',
    verbose=0
)

gauss=optimal_params.fit(X_train_norm,y_train)
print(f'os melhores parametros são {optimal_params.best_params_}')
#Matriz de Confusão do treino
plot_confusion_matrix(gauss,X_train_norm,y_train,values_format='d',display_labels=['0','1','2','3'])

SVC(random_state=393)

#Matriz de Confusão do teste de predição
y_pred=gauss.predict(X_test_norm)
matriz=plot_confusion_matrix(gauss,X_test_norm,y_test,values_format='d',display_labels=['0','1','2','3'])


metricas = pd.DataFrame(index = ['acuracia','precisao','sensitividade','f1_score'],columns=['0','1','2','3'])
metricas.iloc[0] = accuracy_score(y_test, y_pred)
metricas.iloc[1] = precision_score(y_test, y_pred, average=None)
metricas.iloc[2] = recall_score(y_test, y_pred, average=None)
metricas.iloc[3] = f1_score(y_test, y_pred, average=None)

print('Métricas da Matriz de Confusão de Teste (54 elementos de cada classe):')
print(metricas)




#Outros testes com resultados relevantes.



print('\n\n\nFiltro que Obteve a segunda Maior acurácia em relação aos testados:\n\n\n')


param_grid = [
    {'C':[0.5,1,3,5,10,100],
     'gamma':['scale',1,0.1,0.01,0.001,0.0001],
     'degree':[0,0.1,0.5,1,1.5,2,2.5,3,3.5,4,4.5,5],
     'kernel':['poly']}
]
optimal_params = model_selection.GridSearchCV(
    SVC(random_state=393),
    param_grid,
    cv=10,
    scoring='accuracy',
    verbose=0
) 
poly=optimal_params.fit(X_train_norm,y_train)
print(optimal_params.best_params_)
#plot_confusion_matrix(poly,X_train_norm,y_train,values_format='d',display_labels=['0','1','2','3'])

SVC(random_state=393)
y_pred=poly.predict(X_test_norm)
#plot_confusion_matrix(poly,X_test_norm,y_test,values_format='d',display_labels=['0','1','2','3'])

metricas = pd.DataFrame(index = ['acuracia','precisao','sensitividade','f1_score'],columns=['0','1','2','3'])
metricas.iloc[0] = accuracy_score(y_test, y_pred)
metricas.iloc[1] = precision_score(y_test, y_pred, average=None)
metricas.iloc[2] = recall_score(y_test, y_pred, average=None)
metricas.iloc[3] = f1_score(y_test, y_pred, average=None)

print('Métricas da Matriz de Confusão de Teste (54 elementos de cada classe):')
print(metricas)



print('\n\n\n Filtros que teve acurácia relevante:\n\n\n')



param_grid = [
    {'C':[0.5,1,3,5,10,100],
     'gamma':['scale',1,0.1,0.01,0.001,0.0001],
     'kernel':['sigmoid']}
]
optimal_params = model_selection.GridSearchCV(
    SVC(random_state=393),
    param_grid,
    cv=10,
    scoring='accuracy',
    verbose=0
)
sigmoid=optimal_params.fit(X_train_norm,y_train)
print(optimal_params.best_params_)
#mat_train = plot_confusion_matrix(sigmoid,X_train_norm,y_train,values_format='d',display_labels=['0','1','2','3'])

SVC(random_state=393)
y_pred=sigmoid.predict(X_test_norm)
#mat_test = plot_confusion_matrix(sigmoid,X_test_norm,y_test,values_format='d',display_labels=['0','1','2','3'])

metricas = pd.DataFrame(index = ['acuracia','precisao','sensitividade','f1_score'],columns=['0','1','2','3'])
metricas.iloc[0] = accuracy_score(y_test, y_pred)
metricas.iloc[1] = precision_score(y_test, y_pred, average=None)
metricas.iloc[2] = recall_score(y_test, y_pred, average=None)
metricas.iloc[3] = f1_score(y_test, y_pred, average=None)

print('Métricas da Matriz de Confusão de Teste (54 elementos de cada classe):')
print(metricas)



print('\n\n\n Filtro que teve acurácia relevantes:\n\n\n')



param_grid = [
    {'C':[0.5,1,3,5,10,100],
     'kernel':['linear']}
]

optimal_params = model_selection.GridSearchCV(
    SVC(random_state=393),
    param_grid,
    cv=10,
    scoring='accuracy',
    verbose=0
)

linear=optimal_params.fit(X_train_norm,y_train)
print(optimal_params.best_params_)
#mat_train=plot_confusion_matrix(linear,X_train_norm,y_train,values_format='d',display_labels=['0','1','2','3'])

SVC(random_state=393)
y_pred=linear.predict(X_test_norm)
#mat_test = plot_confusion_matrix(linear,X_test_norm,y_test,values_format='d',display_labels=['0','1','2','3'])

metricas = pd.DataFrame(index = ['acuracia','precisao','sensitividade','f1_score'],columns=['0','1','2','3'])
metricas.iloc[0] = accuracy_score(y_test, y_pred)
metricas.iloc[1] = precision_score(y_test, y_pred, average=None)
metricas.iloc[2] = recall_score(y_test, y_pred, average=None)
metricas.iloc[3] = f1_score(y_test, y_pred, average=None)

print('Métricas da Matriz de Confusão de Teste (54 elementos de cada classe):')
print(metricas)

print('\n\n\n Fim  da compilação do código, seguem as as matrizes de confusão de treino e teste do melhor resultado:\n\n\n')


plt.show()